{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "running-dfu-image-augmentation-pipeline",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyORgndhrOKlik87rJ9cdkB8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnshsrs/image_augmentation/blob/main/running_dfu_image_augmentation_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdtLNfO_anVN"
      },
      "source": [
        "# Install and Load Packages\n",
        "\n",
        "Installation is required each time this notenook runs.\n",
        "\n",
        "Storing the image data, the Google Drive is mounted for this notebook.\n",
        "\n",
        "Then, packages are imported.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9sfDrIm7H6f",
        "outputId": "cdbb1f80-d81c-4f1a-9366-e5cc881c23a9"
      },
      "source": [
        "!pip install -U git+https://github.com/albumentations-team/albumentations"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/albumentations-team/albumentations\n",
            "  Cloning https://github.com/albumentations-team/albumentations to /tmp/pip-req-build-gz3hdk9t\n",
            "  Running command git clone -q https://github.com/albumentations-team/albumentations /tmp/pip-req-build-gz3hdk9t\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations==0.5.2) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (1.15.0)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.5.2-cp37-none-any.whl size=97039 sha256=f37953a5d840ef88a16fefd0bf5e46b6c8bb4493c66bea0c55cc357e5f6c314e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c61epauz/wheels/6f/77/82/86baf8aeda64a6de0f890cd0f2fb31acaf5545cc9c99ad21ba\n",
            "Successfully built albumentations\n",
            "Installing collected packages: albumentations\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OsMPdBa4KOj",
        "outputId": "9c934be0-2ed9-45a6-fe7b-0b8ccfb4fb06"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/diabetic-foot-ulcer')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/diabetic-foot-ulcer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxR49NvX3fb-"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfBqK3VL3hZo"
      },
      "source": [
        "import random\n",
        "\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "import os\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHyM3ueeiMSn"
      },
      "source": [
        "# Define Functions\n",
        "\n",
        "## Display of Bounding Boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLOVKbh63mWX"
      },
      "source": [
        "# Preparation\n",
        "\n",
        "## Define the display of Bounding Boxes\n",
        "BOX_COLOR = (255, 0, 0) # Red\n",
        "TEXT_COLOR = (255, 255, 255) # White\n",
        "\n",
        "def visualize_bbox(img, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
        "    \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
        "    \n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)\n",
        "\n",
        "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
        "\n",
        "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
        "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
        "    cv2.putText(\n",
        "        img,\n",
        "        text=class_name,\n",
        "        org=(x_min, y_min - int(0.3 * text_height)),\n",
        "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        fontScale=0.35, \n",
        "        color=TEXT_COLOR, \n",
        "        lineType=cv2.LINE_AA,\n",
        "    )\n",
        "    return img\n",
        "\n",
        "\n",
        "def visualize(image, bboxes, category_ids, category_id_to_name):\n",
        "    img = image.copy()\n",
        "    for bbox, category_id in zip(bboxes, category_ids):\n",
        "        class_name = category_id_to_name[category_id]\n",
        "        img = visualize_bbox(img, bbox, class_name)\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omvR5ldKtn1U"
      },
      "source": [
        "## Get file names of PASCAL VOC Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exYHBTT0oRMP"
      },
      "source": [
        "## Import of Bounding Boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWfDZjJ3wdhI"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def read_content(xml_file: str):\n",
        "\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # filename = root.find('filename').text\n",
        "    filename = xml_file.replace(\".xml\", \".jpg\")\n",
        "    list_with_all_boxes = []\n",
        "\n",
        "    for boxes in root.iter('object'):\n",
        "\n",
        "        ymin, xmin, ymax, xmax = None, None, None, None\n",
        "\n",
        "        ymin = int(boxes.find(\"bndbox/ymin\").text)\n",
        "        xmin = int(boxes.find(\"bndbox/xmin\").text)\n",
        "        ymax = int(boxes.find(\"bndbox/ymax\").text)\n",
        "        xmax = int(boxes.find(\"bndbox/xmax\").text)\n",
        "\n",
        "        list_with_single_boxes = [xmin, ymin, xmax, ymax]\n",
        "        list_with_all_boxes.append(list_with_single_boxes)\n",
        "\n",
        "    return filename, list_with_all_boxes"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmcqCeCvbZE2"
      },
      "source": [
        "In this project uses the *pascal yolo* format.\n",
        "\n",
        "[Yolo Format](https://albumentations.ai/docs/images/getting_started/augmenting_bboxes/bbox_example.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MrPoXWZrK9h"
      },
      "source": [
        "## Write Transformed Pascal VOC bboxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5wMTvVrrKRb",
        "outputId": "fd4e995c-b24d-4a20-c19d-421d27ea539d"
      },
      "source": [
        "!pip install pascal-voc-writer\n",
        "\n",
        "# Writer(path, width, height)\n",
        "from pascal_voc_writer import Writer\n",
        "\n",
        "def write_augmented_pascalvoc_bboxes(bboxes, fpath_and_fname_of_augmented_img, transformed_image):\n",
        "\n",
        "  writer = Writer(fpath_and_fname_of_augmented_img, transformed_image.shape[0], transformed_image.shape[1])\n",
        "\n",
        "  for i in range(len(bboxes)):\n",
        "    xmin, ymin, xmax, ymax = bboxes[i]\n",
        "    xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n",
        "    label = transformed_labels[i]\n",
        "    writer.addObject(label, xmin, ymin, xmax, ymax)\n",
        "\n",
        "  xml_fpath_and_fname = fpath_and_fname_of_augmented_img.replace(\".jpg\", \".xml\")\n",
        "\n",
        "  writer.save(xml_fpath_and_fname)\n",
        "  print(\"BBOXES saved: \" + xml_fpath_and_fname)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pascal-voc-writer\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/82/dd86999e6062fc34478f11ead7a68e6615d7e270b39624547edd1dbaba76/pascal_voc_writer-0.1.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pascal-voc-writer) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pascal-voc-writer) (2.0.1)\n",
            "Installing collected packages: pascal-voc-writer\n",
            "Successfully installed pascal-voc-writer-0.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c55rqYy9hpxQ"
      },
      "source": [
        "# Import Raw Data (bboxes and images)\n",
        "\n",
        "First, the pascal voc, which is a xml file, is read.\n",
        "Then, the jpg-image, which has the same file name as the xml file, is loaded and visualized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIFJXrqe5jey"
      },
      "source": [
        "# specify the location of the images (should contain the bbox files as well)\n",
        "fpath = \"/content/diabetic-foot-ulcer/MyDrive/images-annotated/\"\n",
        "\n",
        "\n",
        "files = []\n",
        "for file in os.listdir(fpath):\n",
        "    if file.endswith(\".xml\"):\n",
        "        files.append(os.path.join(fpath, file))\n",
        "\n",
        "pascal_voc_bbox = files[1]\n",
        "\n",
        "img_name, bboxes = read_content(pascal_voc_bbox)\n",
        "\n",
        "image = cv2.imread(img_name)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "dim = (800, 800)\n",
        "category_ids = [1]\n",
        "category_id_to_name = {1: 'dfu'}\n",
        "\n",
        "# raw image with bounding boxes\n",
        "visualize(image, bboxes, category_ids, category_id_to_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNdkpGhNiDEI"
      },
      "source": [
        "# Simple resize transformation procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoL06hSRiC3B"
      },
      "source": [
        "# resize image\n",
        "image_ = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
        "image_ = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "cv2_imshow(image_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhlSxLEdrAIx"
      },
      "source": [
        "# Define Transformation Pipeline\n",
        "\n",
        "1. Transformation with multiple steps\n",
        "2. Resize of the Raw Image without further augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCgOL24DrABL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzW_p8MS69wV",
        "outputId": "27aaf6a2-b3e8-49ce-b399-1c0e84e64e16"
      },
      "source": [
        "trans = [\n",
        "    A.Resize(800, 800),\n",
        "    A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=.4), \n",
        "    A.HueSaturationValue(p=.1, hue_shift_limit=5, sat_shift_limit=5, val_shift_limit=5),\n",
        "    A.GaussianBlur(blur_limit=3, p=.2),\n",
        "    A.MedianBlur(blur_limit=3, p=.2),\n",
        "    A.RandomBrightnessContrast(brightness_limit=.2, contrast_limit=.2, p=1),\n",
        "    A.ShiftScaleRotate(p=1),\n",
        "    A.Rotate(p=.8),\n",
        "    A.HorizontalFlip(p=.7)]\n",
        "\n",
        "transform = A.Compose(\n",
        "    trans,\n",
        "    bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.3, label_fields=['class_labels'])\n",
        ")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/albumentations/augmentations/transforms.py:1852: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
            "  \"blur_limit and sigma_limit minimum value can not be both equal to 0. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGiVhkgNS_3X"
      },
      "source": [
        "trans_resize = [A.Resize(800, 800)]\n",
        "transform_resize = A.Compose(trans_resize, bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.3, label_fields=['class_labels']))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8z4TT_ErWwN"
      },
      "source": [
        "## Define Metadata of the Image\n",
        "\n",
        "1. Category ID\n",
        "2. Category Label (dict)\n",
        "3. Dimensions of resized images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz0u8DT_sIcP"
      },
      "source": [
        "dim = (800, 800)\n",
        "class_labels = [1]\n",
        "category_id_to_name = {1: 'dfu'}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAd19NUrr4b-"
      },
      "source": [
        "# Bulk Import of Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp_HxP2zn4Ib"
      },
      "source": [
        "fpath = \"/content/diabetic-foot-ulcer/MyDrive/images-annotated/\"\n",
        "\n",
        "\n",
        "files = []\n",
        "for file in os.listdir(fpath):\n",
        "    if file.endswith(\".xml\"):\n",
        "        files.append(os.path.join(fpath, file))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6xB59blxkEU"
      },
      "source": [
        "\n",
        "# Define File Path of Images with Annotations\n",
        "fpath = \"/content/diabetic-foot-ulcer/MyDrive/images-annotated/\"\n",
        "folder_for_augmented_images = \"/content/diabetic-foot-ulcer/MyDrive/images-augmentated/\"\n",
        "\n",
        "# Get all Pascal VOC XML Files\n",
        "\n",
        "#pascal_files = get_pascal_voc(fpath)\n",
        "#print(pascal_files)\n",
        "\n",
        "for f in files[1]:\n",
        "  \n",
        "  raw_img_name, raw_img_bboxes = read_content(f)\n",
        "  \n",
        "  if len(raw_img_bboxes) == 1:\n",
        "    print(\"I start augmenting!\")\n",
        "    try:\n",
        "      f = open(raw_img_name)\n",
        "      # Do something with the file\n",
        "    except IOError:\n",
        "        print(\"File not accessible\")\n",
        "    finally:\n",
        "        f.close()\n",
        "\n",
        "    for i in range(10):\n",
        "      image_ = cv2.imread(raw_img_name)\n",
        "      image_ = cv2.cvtColor(image_, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      # Augment labels\n",
        "      transformed = transform(image = image_, bboxes=raw_img_bboxes, class_labels=class_labels)\n",
        "\n",
        "      # Get objects from transformed label\n",
        "      transformed_image = transformed['image']\n",
        "      transformed_bboxes = transformed['bboxes']\n",
        "      transformed_labels = transformed['class_labels']\n",
        "\n",
        "      # cv2_imshow(transformed_image)\n",
        "      # new image name\n",
        "      fname = '_{:02}'.format(i) + \".jpg\"\n",
        "      file_path_for_augmented_image = raw_img_name.replace('.jpg', fname)\n",
        "      fname_augmented_image = file_path_for_augmented_image.split(\"/\")[-1]\n",
        "      \n",
        "\n",
        "      path_to_store_augmented_image_in_loop = folder_for_augmented_images + fname_augmented_image\n",
        "\n",
        "      #cv2_imshow(transformed_image)\n",
        "      # Write bboxes for augmented images\n",
        "      write_augmented_pascalvoc_bboxes(bboxes = transformed_bboxes,\n",
        "                                      fpath_and_fname_of_augmented_img = path_to_store_augmented_image_in_loop,\n",
        "                                      transformed_image = transformed_image)\n",
        "      \n",
        "      # Save transformed image\n",
        "      transformed_image_rgb = cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB)\n",
        "      # cv2_imshow(transformed_image_rgb)\n",
        "      cv2.imwrite(path_to_store_augmented_image_in_loop, transformed_image_rgb)\n",
        "\n",
        "  else:\n",
        "    print(\"Skipped; Number of BBoxes > 1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA2pBTYAjOWS"
      },
      "source": [
        "files[:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}